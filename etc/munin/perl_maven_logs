#!/usr/bin/perl
use strict;
use warnings;
use 5.010;

use File::Basename qw(basename);
use POSIX;
use JSON::XS qw(encode_json decode_json);
use Time::HiRes ();

my $daily_data_file = '/tmp/perl_maven_logs_daily.json';
my $data_file       = '/tmp/perl_maven_logs.json';
my $size_file       = '/tmp/perl_maven_logs.size';

my $start_time = Time::HiRes::time;

if (@ARGV) {
	if ( $ARGV[0] eq 'collect' ) {
		collect();

	}
	if ( $ARGV[0] eq 'config' ) {

		if ( basename($0) eq 'perl_maven_logs_time' ) {
			print <<"END_CONFIG";
graph_title Average request processing time
graph_vlabel sec
graph_category PerlMaven
END_CONFIG
			say 'average_time_5min.label Average request time (last 5 min)';
			say 'average_time_daily.label Average request time (last 24 hours)';
			exit;
		}

		if ( basename($0) eq 'perl_maven_logs_processing' ) {
			print <<"END_CONFIG";
graph_title Log file processing
graph_vlabel sec
graph_category PerlMaven
END_CONFIG
			say 'processing_time.label Processing time';
			exit;
		}

		my $data = read_file($data_file) || {};

		if ( basename($0) eq 'perl_maven_logs_hostnames' ) {
			print <<"END_CONFIG";
graph_title Page view per domain (last 5 min)
graph_vlabel cnt
graph_category PerlMaven
END_CONFIG

			foreach my $host ( keys %{ $data->{hosts} } ) {
				my $name = $host;
				$name =~ s/\./_/g;
				say "$name.label $host";
			}
			exit;
		}

		if ( basename($0) eq 'perl_maven_logs_hostnames_daily' ) {
			print <<"END_CONFIG";
graph_title Page view per domain (last 24 hours)
graph_vlabel cnt
graph_category PerlMaven
END_CONFIG

			foreach my $host ( keys %{ $data->{daily}{hosts} } ) {
				my $name = $host;
				$name =~ s/\./_/g;
				say "$name.label $host";
			}
			exit;
		}

		if ( basename($0) eq 'perl_maven_logs_translations_daily' ) {
			print <<"END_CONFIG";
graph_title Page view per domain (last 24 hours)
graph_vlabel cnt
graph_category PerlMaven
END_CONFIG

			foreach my $host ( keys %{ $data->{daily}{hosts} } ) {
				next if $host eq 'perlmaven.com';    # TODO remove hardcoding
				my $name = $host;
				$name =~ s/\./_/g;
				say "$name.label $host";
			}
			exit;
		}

	}
}
else {
	my $data = read_file($data_file) || {};

	if ( basename($0) eq 'perl_maven_logs_time' ) {
		say 'average_time_5min.value ' . ( $data->{total}{cnt} ? $data->{total}{time} / $data->{total}{cnt} : 0 );
		say 'average_time_daily.value '
			. ( $data->{daily}{total}{cnt} ? $data->{daily}{total}{time} / $data->{daily}{total}{cnt} : 0 );
		exit;
	}

	if ( basename($0) eq 'perl_maven_logs_processing' ) {
		say "processing_time.value $data->{processing_time}";
		exit;
	}

	if ( basename($0) eq 'perl_maven_logs_hostnames' ) {
		foreach my $host ( keys %{ $data->{hosts} } ) {
			my $name = $host;
			$name =~ s/\./_/g;
			say "$name.value $data->{hosts}{$host}";
		}
		exit;
	}

	if ( basename($0) eq 'perl_maven_logs_hostnames_daily' ) {
		foreach my $host ( keys %{ $data->{daily}{hosts} } ) {
			my $name = $host;
			$name =~ s/\./_/g;
			say "$name.value $data->{daily}{hosts}{$host}";
		}
		exit;
	}

	if ( basename($0) eq 'perl_maven_logs_translations_daily' ) {
		foreach my $host ( keys %{ $data->{daily}{hosts} } ) {
			next if $host eq 'perlmaven.com';    # TODO remove hardcoding
			my $name = $host;
			$name =~ s/\./_/g;
			say "$name.value $data->{daily}{hosts}{$host}";
		}
		exit;
	}
}

sub read_file {
	my ($file) = @_;

	my $json;
	if ( open my $fh, '<', $file ) {
		local $/ = undef;
		$json = <$fh>;
		close $fh;
	}
	return if not $json;
	return decode_json $json;
}

sub save_file {
	my ( $file, $text ) = @_;
	open my $out, '>', $file or die "Cannot open '$file' for writing";
	print $out $text;
	close $out;
	return;
}

sub process {
	my ( $file, $location, $data ) = @_;

	#print "Processing $file\n";
	my $cnt = 0;

	my $size = -s $file;
	open my $fh, '<', $file or die "Could not open '$file' for reading";
	seek $fh, $location, 0;
	while ( my $row = <$fh> ) {
		$cnt++;
		chomp $row;
		eval {
			my $entry = decode_json $row;
			if ( defined $entry->{host} ) {
				$data->{hosts}{ $entry->{host} }++;
			}
			else {
				warn "host is missing in line '$row'";
			}
			if ( defined $entry->{elapsed_time} ) {
				$data->{total}{time} += $entry->{elapsed_time};
				$data->{total}{cnt}++;
			}
			1;
		} or do {
			my $err = $@ // 'Unknown error';
			warn "$err  while trying to parse ($cnt) '$row'";
		};
	}

	return $size;
}

sub collect {
	my $time      = time;
	my $this_file = 'logs/' . POSIX::strftime( '%Y-%m-%d-requests.log', gmtime($time) );
	my $prev_file = 'logs/' . POSIX::strftime( '%Y-%m-%d-requests.log', gmtime( $time - 24 * 60 * 60 ) );

	#say $this_file;
	#say $prev_file;

	return if not -e $this_file;

	if ( not -e $size_file ) {
		save_file( $size_file, -s $this_file );
		return;
	}

	open my $fh, '<', $size_file or die "Cannot open '$size_file' for reading";
	my $last_size = <$fh>;
	close $fh;

	my %data;
	if ( -s $this_file < $last_size ) {    # TODO add a condition on time as well!
		if ( -e $prev_file ) {
			process( $prev_file, $last_size, \%data );
		}
	}
	$last_size = process( $this_file, $last_size, \%data );

	# The daily file is a list of hashes;
	# each hash contains the data for a 5-min intervall and the timestamp when
	# the processing of that 5-min intervall started.
	# The file contains the data for one day.
	my $daily = read_file($daily_data_file) || [];
	push @$daily,
		{
		start_time => $start_time,
		data       => \%data,
		};
	while ( $daily->[0]{start_time} < Time::HiRes::time - 60 * 60 * 24 ) {
		shift @$daily;
	}
	save_file( $daily_data_file, encode_json($daily) );

	my %collected = (
		total => {
			time => 0,
			cnt  => 0,
		},
	);
	foreach my $entry (@$daily) {
		$collected{total}{time} += $entry->{data}{total}{time} || 0;
		$collected{total}{cnt}  += $entry->{data}{total}{cnt}  || 0;
		foreach my $host ( keys %{ $entry->{data}{hosts} } ) {
			$collected{hosts}{$host} ||= 0;
			$collected{hosts}{$host} += $entry->{data}{hosts}{$host};
		}
	}
	$data{daily} = \%collected;

	$data{processing_time} = Time::HiRes::time - $start_time;
	save_file( $data_file, encode_json( \%data ) );
	save_file( $size_file, $last_size );

}

